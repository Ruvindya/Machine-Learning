{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyBKIDpNxHV5A3eFkscVuK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruvindya/Machine-Learning/blob/main/Lab03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LAB 03 2019E117"
      ],
      "metadata": {
        "id": "5yoAalDDsMsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Study the dataset ’Fashion-MNIST’ in Keras. Answer the following questions in relation to the above dataset."
      ],
      "metadata": {
        "id": "yZbJJDmFsUQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Find out whether it can be used for regression or classification."
      ],
      "metadata": {
        "id": "qeWaKZNcswxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   It is used fot classification."
      ],
      "metadata": {
        "id": "06f1jP7JtHXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) What is the size of the images?"
      ],
      "metadata": {
        "id": "xTjzs4EYtYyl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K5fyQi_mr4ML"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = train_images.shape[1:]  # Shape of the train_images excluding the number of samples\n",
        "print(\"Size of the images:\")\n",
        "image_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jyDBFbxtgTU",
        "outputId": "2c5a0b4c-230c-44ff-eb76-0e59f20bea6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the images:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) How many images are there in the train data?"
      ],
      "metadata": {
        "id": "qGFqvtrkuRb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_images = train_images.shape[0]\n",
        "print(\"Number of images in the train data:\",num_train_images)\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnpEFLvjuCR_",
        "outputId": "77b34065-67ff-486e-cfc2-bf52b6e8c975"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the train data: 60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) State the number of images in test data."
      ],
      "metadata": {
        "id": "WvBACQoUu4fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_test_images = test_images.shape[0]\n",
        "print(\"Number of images in the test data:\", num_test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtq9FrThunHI",
        "outputId": "ae603ddc-dfc4-47fb-dec1-8b6f85dabd18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the test data: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) How many classes are there in the data? Write down those classes."
      ],
      "metadata": {
        "id": "gJb1jSBIvVN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(set(train_labels))\n",
        "class_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "print(\"Number of classes:\", num_classes)\n",
        "print(\"Class labels:\", class_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx0l6UDmvMWp",
        "outputId": "6d9c4cf9-3bef-408d-89ce-ed983acd333f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 10\n",
            "Class labels: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Load that dataset directly from Keras using Python."
      ],
      "metadata": {
        "id": "57g5AH7Gwh__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "3k_ncWzRvkzT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. View some images in training data, for example draw the 11th image in your training data."
      ],
      "metadata": {
        "id": "AWxX0sqCyp3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_images[100], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "6YTxuhn4ySOk",
        "outputId": "f973ba4a-3040-413c-b10d-6fc1f7832892"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Normalize your data (train and test) between 0 and 1.\n",
        "Hint: This is a grayscale image has pixel values between 0 and 255."
      ],
      "metadata": {
        "id": "wvJTzCSbziZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "DHkLwW9ky3Hj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Now divide the training data into two: \n",
        "Validation images (first 5000 images from the initial training data) and Training images (rest of the images in your initial training data)."
      ],
      "metadata": {
        "id": "Rr6JoolTzvSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_images = train_images[:5000]\n",
        "val_labels = train_labels[:5000]\n",
        "train_images = train_images[5000:]\n",
        "train_labels = train_labels[5000:]"
      ],
      "metadata": {
        "id": "ewFOxHIUztsq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Initialize the weight and bias parameters of your model.\n"
      ],
      "metadata": {
        "id": "2J2aDc6q0K0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
        "bias_init = keras.initializers.Zeros()"
      ],
      "metadata": {
        "id": "pWyOSq360Hv6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Now build the neural network model with the following characteristics:\n",
        "(a) One Flatten layer as the input layer.\n",
        "(b) Two dense relu layers as hidden layers.\n"
      ],
      "metadata": {
        "id": "Lgd1ljHZ0-9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(256, activation='relu', kernel_initializer=weight_init, bias_initializer=bias_init),\n",
        "    keras.layers.Dense(128, activation='relu', kernel_initializer=weight_init, bias_initializer=bias_init),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXetFNgb066p",
        "outputId": "67140249-ae60-49a1-d249-195df69f5535"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxOO56_y1HxA",
        "outputId": "f2f9225c-df25-4c08-a907-4e6d488587b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with desired loss function, optimizer, and metrics\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OF_6xlar1MUo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training data and validate\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(val_images, val_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsJn1OJy1TDp",
        "outputId": "8a5e021c-e614-4415-c70b-3dccb5828ec7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.5019 - accuracy: 0.8183 - val_loss: 0.4099 - val_accuracy: 0.8524\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3711 - accuracy: 0.8632 - val_loss: 0.3456 - val_accuracy: 0.8752\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3324 - accuracy: 0.8788 - val_loss: 0.3414 - val_accuracy: 0.8776\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 13s 7ms/step - loss: 0.3089 - accuracy: 0.8847 - val_loss: 0.3275 - val_accuracy: 0.8782\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 14s 8ms/step - loss: 0.2890 - accuracy: 0.8912 - val_loss: 0.3232 - val_accuracy: 0.8860\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2732 - accuracy: 0.8976 - val_loss: 0.3015 - val_accuracy: 0.8944\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2640 - accuracy: 0.9001 - val_loss: 0.2980 - val_accuracy: 0.8922\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2511 - accuracy: 0.9054 - val_loss: 0.2924 - val_accuracy: 0.8982\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.2409 - accuracy: 0.9091 - val_loss: 0.2975 - val_accuracy: 0.8944\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2289 - accuracy: 0.9130 - val_loss: 0.3124 - val_accuracy: 0.8926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Accuracy on test data:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcYR3n0D1V5w",
        "outputId": "09c67fa7-4eb5-4314-ffe5-5451719f9a47"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3476 - accuracy: 0.8814\n",
            "Accuracy on test data: 0.8813999891281128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the target classes for the first five samples of the test data\n",
        "predictions = model.predict(test_images[:5])\n",
        "predicted_classes = [class_labels[prediction.argmax()] for prediction in predictions]\n",
        "actual_classes = [class_labels[label] for label in test_labels[:5]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-nrTr_n16Wd",
        "outputId": "88d30a1f-8e93-437f-e616-f53d6dbba7bd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 214ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the actual and predicted target classes\n",
        "for i in range(5):\n",
        "    print(\"Actual:\", actual_classes[i], \"Predicted:\", predicted_classes[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNEHC7CE1_mJ",
        "outputId": "b72419e7-4254-4842-e615-26327716d32e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: Ankle boot Predicted: Ankle boot\n",
            "Actual: Pullover Predicted: Pullover\n",
            "Actual: Trouser Predicted: Trouser\n",
            "Actual: Trouser Predicted: Trouser\n",
            "Actual: Shirt Predicted: T-shirt/top\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G5Fl51cl2EAZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}